"""Using batch gradient descent in a three layer neural network, to classify the MNIST dataset images """

import sys, numpy as np
from keras.datasets import mnist

(x_train, y_train), (x_test, y_test) = mnist.load_data()

images = x_train[0:1000].reshape(1000, 28*28) / 255
labels = y_train[0:1000]
one_hot_encode = np.zeros((len(labels), 10))

for i, l in enumerate(labels):      # Takes the index and the value of a label(from the labels matrix),   
    one_hot_encode[i][l] = 1        # -then goes to the same row-index and label-(column)index on the one-hot matrix, making the value equal to 1 (one-hot encoding).
labels = one_hot_encode             # The one-hot matrix then becomes the labels matrix, making the labels one-hot encoded.
   

t_images = x_test[0:1000].reshape(1000, 28*28) / 255
t_labels = np.zeros((len(y_test), 10))
for i, l in enumerate(y_test):
    t_labels[i][l] = 1

np.random.seed(1)
relu = lambda x: (x >= 0)*x
reluderivative = lambda x: x >= 0

batch_size = 100 # The size of the batch
alpha = 0.001
iterations = 360
px_per_img = 784
hidden_size = 100
n_labels = 10    # One label for each number up to 10 (or from 0 to 9 - I'm not sure at the moment)



weights_0 = 0.2 * np.random.random((px_per_img, hidden_size)) - 0.1  #The process of scaling the weights
weights_1 = 0.2 * np.random.random((hidden_size, n_labels)) - 0.1    #The process of scaling the weights

for j in range(iterations):
    error, correct_count = (0.0, 0)
    for i in range(int(len(images) / batch_size)):    # In this case, 1000 / 100 = 10
        batch_start, batch_end = ((i * batch_size), ((i+1) * batch_size))  # E.g if i=0 -> batch_start = 0*100, batch_end = 1*100, and so on...
        
        layer_0 = images[batch_start: batch_end]
        
        layer_1 = relu(np.dot(layer_0, weights_0))
        dropout_mask = np.random.randint(2, size=layer_1.shape)
        layer_1 *= dropout_mask * 2  # The dropout mask is multiplied by 2, so the layer_2 doesn't increase its sensitivity to layer_1  
        
        layer_2 =np.dot(layer_1, weights_1) 
                       
        error += np.sum((labels[batch_start: batch_end] - layer_2)**2)
        for k in range(batch_size): # 0-100
            correct_count += int(np.argmax(layer_2[k:k+1]) == np.argmax(labels[batch_start+k: batch_start+k+1])) 
            """ Compares the biggest value in layer_2[k: k+1] with the biggest value in 100 labels from the labels set, if they are the same, returns True,
            int(True) = 1 and correct_count += 1; If not the same, it returns False, int(False) = 0 and correct_count += 0."""
            
            layer2_delta = (labels[batch_start: batch_end] - layer_2) / batch_size
        
            layer1_delta = layer2_delta.dot(weights_1.T) * reluderivative(layer_1) 
            layer1_delta *= dropout_mask

            weights_0 += alpha * layer_0.T.dot(layer1_delta)
            weights_1 += alpha * layer_1.T.dot(layer2_delta)

# Every 10 iterations, we test the neural network. We then print the results of the training and the tests simultanously.
    if j%10 == 0: 
        t_error, t_correct_count = (0.0, 0)
        for i in range(len(t_images)):
            layer_0 = t_images[i: i+1]
            layer_1 = relu(np.dot(layer_0, weights_0)) 
            layer_2 =np.dot(layer_1, weights_1) 
                       
            t_error += np.sum((t_labels[i: i+1] - layer_2)**2)
            t_correct_count += int(np.argmax(t_labels[i: i+1]) == np.argmax(layer_2))



    
        sys.stdout.write("\n"+ \
                         " I:" + str(j) + \
                         " Test-Error:" + str(t_error/ float(len(t_images))) [0:5] +\
                         " Test-Accuracy:" + str(t_correct_count/ float(len(t_images))) +\
                         " Train-Error:" + str(error / float(len(images)))[0:5] + \
                         " Train-Accuracy:" + str(correct_count / float(len(images)))
                        )
    

